{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8btHNo7H5Cf"
   },
   "source": [
    "# Organize ML projects with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yK9CuWlH5Ch"
   },
   "source": [
    "While Machine Learning is powerful, people often overestimate it: apply machine learning to your project, and all your problems will be solved. In reality, it's not this simple. To be effective, one needs to organize the work very well. In this notebook, we will walkthrough practical aspects of a ML project. To look at the big picture, let's start with a checklist below. It should work reasonably well for most ML projects, but make sure to adapt it to your needs:\n",
    "\n",
    "**1. Define the scope of work and objective**\n",
    "    * How is your solution be used?\n",
    "    * How should performance be measured? Are there any contraints?\n",
    "    * How would the problem be solved manually?\n",
    "    * List the available assumptions, and verify if possible.\n",
    "    \n",
    "    \n",
    "**2. Get the data**\n",
    "    * Document where you can get that data\n",
    "    * Store data in a workspace you can easily access\n",
    "    * Convert the data to a format you can easily manipulate\n",
    "    * Check the overview (size, type, sample, description, statistics)\n",
    "    * Data cleaning\n",
    "    \n",
    "    \n",
    "**3. EDA & Data transformation**\n",
    "    * Study each attribute and its characteristics (missing values, type of distribution, usefulness)\n",
    "    * Visualize the data\n",
    "    * Study the correlations between attributes\n",
    "    * Feature selection, Feature Engineering, Feature scaling\n",
    "    * Write functions for all data transformations\n",
    "    \n",
    "    \n",
    "**4. Train models**\n",
    "    * Automate as much as possible\n",
    "    * Train promising models quickly using standard parameters. Measure and compare their performance\n",
    "    * Analyze the errors the models make\n",
    "    * Shortlist the top three of five most promising models, preferring models that make different types of errors.\n",
    "\n",
    "\n",
    "**5. Fine-tunning**\n",
    "    * Treat data transformation choices as hyperparameters, expecially when you are not sure about them (e.g., replace missing values with zeros or with the median value)\n",
    "    * Unless there are very few hyperparameter value to explore, prefer random search over grid search.\n",
    "    * Try ensemble methods\n",
    "    * Test your final model on the test set to estimate the generalizaiton error. Don't tweak your model again, you would start overfitting the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofeuKevOH5Ch"
   },
   "source": [
    "## Example: Articles categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2NSUqUEH5Ci"
   },
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5GttlMG-H5Cj"
   },
   "source": [
    "Build a model to determine the categories of articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwbjWOG1H5Ck"
   },
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWq7xex_H5Ck"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9W7Hzt2H5Cp"
   },
   "outputs": [],
   "source": [
    "bbc = pd.read_csv('https://raw.githubusercontent.com/dhminh1024/practice_datasets/master/bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "teb1QvD1H5Cs",
    "outputId": "faabed38-d5a6-4d00-c93e-eb355714420e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>politics</td>\n",
       "      <td>pakistani women  must not hide  hiding women a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>tech</td>\n",
       "      <td>napster offers rented music to go music downlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>tech</td>\n",
       "      <td>hacker threat to apple s itunes users of apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>politics</td>\n",
       "      <td>campaign  cold calls  questioned labour and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>tech</td>\n",
       "      <td>broadband in the uk growing fast high-speed ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                               text\n",
       "1169  politics  pakistani women  must not hide  hiding women a...\n",
       "580       tech  napster offers rented music to go music downlo...\n",
       "2102      tech  hacker threat to apple s itunes users of apple...\n",
       "47    politics  campaign  cold calls  questioned labour and th...\n",
       "1366      tech  broadband in the uk growing fast high-speed ne..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "KBW_Sg2RH5Cy",
    "outputId": "e3beb0e7-0428-460a-837e-ef1cafa19e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   category  2225 non-null   object\n",
      " 1   text      2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "bbc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0pQp2ne2VltI"
   },
   "source": [
    "### Manipulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "rCmQw44pWZTH",
    "outputId": "fae961e4-0361-4647-daee-9a739ab02214"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNWq8i7VYGX9"
   },
   "outputs": [],
   "source": [
    "# Removing special characters and \"trash\"\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    \n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    \n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # removing the nose character for standarization. Convert to lower case\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "467Fyf0TYLTv"
   },
   "outputs": [],
   "source": [
    "# tokenizer and stemming\n",
    "# tokenizer: to break down our twits in individual words\n",
    "# stemming: reducing a word to its root\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Split a text into list of words and apply stemming technic\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5TaF1UYYOvl"
   },
   "outputs": [],
   "source": [
    "# split the dataset in train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = bbc['text']\n",
    "y = bbc['category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9pjXIbUYtY2"
   },
   "source": [
    "### Create Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "0ud6JyCfYxRH",
    "outputId": "9b81e81a-f2c8-4747-9f68-8a7d0cc41c74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=<function preprocessor at 0x0000024C735EC5E8>,\n",
       "                                 smooth_idf=True,\n",
       "                                 stop_words=['i', 'me', 'my', 'mysel...\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenizer_porter at 0x0000024C735EC948>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=0,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Pipeline, LogisticRegression, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words,\n",
    "                        tokenizer=tokenizer_porter,\n",
    "                        preprocessor=preprocessor)\n",
    "\n",
    "clf = Pipeline([('vect', tfidf),\n",
    "                ('clf', LogisticRegression(random_state=0))])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AqzbNY7RZDXi"
   },
   "source": [
    "### Evaluate Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "_Y5AbM5wY8op",
    "outputId": "344966a9-e912-4ce8-da56-f35c565c1a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9820224719101124\n",
      "confusion matrix:\n",
      " [[88  0  1  0  1]\n",
      " [ 0 91  0  0  1]\n",
      " [ 2  0 82  1  0]\n",
      " [ 1  0  0 98  0]\n",
      " [ 0  0  1  0 78]]\n",
      "classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.97      0.98      0.97        90\n",
      "entertainment       1.00      0.99      0.99        92\n",
      "     politics       0.98      0.96      0.97        85\n",
      "        sport       0.99      0.99      0.99        99\n",
      "         tech       0.97      0.99      0.98        79\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Test dataset to evaluate model\n",
    "# classification_report\n",
    "# confusion matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "predictions = clf.predict(X_test)\n",
    "print('accuracy:',accuracy_score(y_test,predictions))\n",
    "print('confusion matrix:\\n',confusion_matrix(y_test,predictions))\n",
    "print('classification report:\\n',classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Weekly-Project-BBC Articles.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
